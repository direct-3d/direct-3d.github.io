<!DOCTYPE html
    PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!-- saved from url=(0045)http://6.869.csail.mit.edu/fa19/schedule.html -->
<html xmlns="http://www.w3.org/1999/xhtml">
<link href="https://fonts.cdnfonts.com/css/chalkduster" rel="stylesheet">
<style>
    @import url('https://fonts.cdnfonts.com/css/chalkduster');
</style>
<script src="./sm/assets/teaser-data.js"></script>


<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>DIRECT-3D: Learning Direct Text-to-3D Generation on Massive Noisy 3D Data</title>
    <link href="style.css" rel="stylesheet" type="text/css">
    <meta name="description"
        content="Project page for &#39;DIRECT-3D: Learning Direct Text-to-3D Generation on Massive Noisy 3D Data.&#39;">
    <!-- <link rel="icon" href="./path.jpg"> -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"
        integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
    <style>

    </style>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Discovering Failure Modes of Text-guided Diffusion Models via Adversarial Search</title>
    <link href="style.css" rel="stylesheet" type="text/css">
    <meta name="description"
        content="Project page for &#39;Discovering Failure Modes of Text-guided Diffusion Models via Adversarial Search.&#39;">
    <!-- <link rel="icon" href="./path.jpeg"> -->
</head>

<body>
    <p class="title">Discovering Failure Modes of Text-guided Diffusion Models via Adversarial Search</p>
    <div style="text-align: center; font-size: 40pt; margin-bottom: 30px">
            <!-- <span>CVPR 2023</span> -->
    </div>
    <p class="author">
        <span class="author"><a target="_blank" href="https://qihao067.github.io/">Qihao Liu</a>&nbsp;<sup>1</sup></span>
        <span class="author"><a target="_blank" href="https://gvrl.mpi-inf.mpg.de/">Adam Kortylewski&nbsp;</a><sup>2,3</sup></span>
        <span class="author"><a target="_blank" href="https://yutongbai.com/">Yutong Bai</a>&nbsp;<sup>1</sup></span>
        <span class="author"><a target="_blank" href="https://songbai.site/">Song Bai</a>&nbsp;<sup>4</sup></span>
        <span class="author"><a target="_blank" href="https://www.cs.jhu.edu/~ayuille/">Alan Yuille</a>&nbsp;<sup>1</sup></span>
    </p>
    <table border="0" align="center" class="affiliations">
        <tbody align="center">
            <tr>
                <td style="text-align: center; width:0%; ">&nbsp;<sup>1</sup>&nbsp;Johns Hopkins University</td>
                <td style="text-align: center; width:0%; ">&nbsp;<sup>2</sup>&nbsp;University of Freiburg</td>
                <td style="text-align: center; width:0%; ">&nbsp;<sup>3</sup>&nbsp;Max-Planck-Institute for Informatics</td>
                <td style="text-align: center; width:0%; ">&nbsp;<sup>4</sup>&nbsp;ByteDance Inc.</td>
            </tr>
        </tbody>
    </table>

    <table width="80%" border="0" align="center" class="menu" style="margin-bottom: 8px;">
        <tbody>
            <tr>
                <td align="center"> <a href="https://arxiv.org/pdf/2306.00974.pdf" target="_blank">[Paper]</a>&emsp;&emsp;<a href="https://sage-diffusion.github.io/file/bibtex.txt">[BibTeX]</a> </td>
            </tr>
        </tbody>
    </table>
    <div class="container">

        &nbsp;<br>
        &nbsp;<br>

        
        <table width="940" border="0">
            <tbody>
                <figure>
                    <img src="./img/AttDis_fig1.jpg" alt="" width="990" style="margin: auto" />
                </figure>

                <ul>
                    <li>We propose SAGE, the first automated method to systematically find failure modes of diffusion models by searching over the discrete prompt space and the high-dimensional latent space.</li>
                    <li>We conduct a comprehensive analysis of the failure modes of SOTA generative models. Our investigation delves deeply into four intriguing unexpected behaviors that have not been systematically studied before.</li>
                </ul>
            </tbody>
        </table>

        &nbsp;<br>
        <hr class="hr-twill-colorful">
        &nbsp;<br>

        <p style="text-align: center;"><span class="section"><strong>Abstract</strong></span></p>
        <p> Text-guided diffusion models (TDMs) are widely applied but can fail unexpectedly. Common failures include: (i) natural-looking text prompts generating images with the wrong content, or (ii) different random samples of the latent variables that generate vastly different, and even unrelated, outputs despite being conditioned on the same text prompt. In this work, we aim to study and understand the failure modes of TDMs in more detail. To achieve this, we propose SAGE, the first adversarial search method on TDMs that systematically explores the discrete prompt space and the high-dimensional latent space, to automatically discover undesirable behaviors and failure cases in image generation. We use image classifiers as surrogate loss functions during searching, and employ human inspections to validate the identified failures. For the first time, our method enables efficient exploration of both the discrete and intricate human language space and the challenging latent space, overcoming the gradient vanishing problem. Then, we demonstrate the effectiveness of SAGE on five widely used generative models and reveal four typical failure modes that have not been systematically studied before: (1) We find a variety of natural text prompts that generate images failing to capture the semantics of input texts. We further discuss the underlying causes and potential solutions based on the results. (2) We find regions in the latent space that lead to distorted images independent of the text prompt, suggesting that parts of the latent space are not well-structured. (3) We also find latent samples that result in natural-looking images unrelated to the text prompt, implying a possible misalignment between the latent and prompt spaces. (4) By appending a single adversarial token embedding to any input prompts, we can generate a variety of specified target objects, with minimal impact on CLIP scores, demonstrating the fragility of language representations.
        <p class="section">&nbsp;</p>

        &nbsp;<br>
        <hr class="hr-twill-colorful">
        &nbsp;<br>

        <p style="text-align: center;"><span class="section"><strong>Method</strong></span></p>
        <p class="section">&nbsp;</p>
        <div style="text-align: center">
            <img src="./img/pipeline.jpg" alt="" width="990" style="margin: auto" />
        </div>
        <p class="section">&nbsp;</p>
        <p> Given a text-guided generative model <i>G</i>, we want to automatically find natural text prompts <i>p</i> or non-outlier latent variables <i>z</i> that generate failure images. We formulate it as an adversarial optimization process. A gradient-guided search policy <i>P</i> is proposed to enable efficient search over the discrete prompt space, and the residual connection is used to back-propagate the gradient from outputs <i>I</i> to the inputs of latent variable. Finally, an ensemble of discriminative models is used to obtain a robust discriminator <i>D</i> to find true failures of the generative model <i>G</i>.</p>
        <p class="section">&nbsp;</p>

        <hr class="hr-twill-colorful">

        <p class="section">&nbsp;</p>

        <p style="text-align: center;"><span class="section"><strong>Typical Failure Modes</strong></span></p>

        <p class="section">&nbsp;</p>

        <p class="section"><b>I.  Natural Text Prompts that are Unintelligible for Diffusion Models</b></p>
        <p> We find a large number of concise text prompts (at most 15 words) that are natural and easily understood by humans but not by the SOTA diffusion models. Current models still struggle to grasp and describe certain linguistic representations. We manually summarize the key features and categorize them into ten distinct types, based on the underlying causes. Current models are good at understanding objects, but may be confused by specific actions ('fighting' in a), and may struggle to understand the relationship between nouns and verbs (b), nouns and adjectives (c), subjects and objects (d), and words with salient features (e). In addition, they often do not comprehend compositions (f), numbers (g), parts (h), viewpoints (i), and fractions (j).</p>
        <div style="text-align: center">
            <img src="./img/EXP-attText.jpg" alt="" width="990" style="margin: auto" />
        </div>
        <p class="section">&nbsp;</p>


        <p class="section"><b>II.  Latent Samples that Lead to Distorted Images</b></p>
        <p> We find samples/regions in the latent space that consistently lead to distorted images under various commonly used prompts, implying that parts of the latent space are not well-structured. We also show that both generative models and discriminative models have representation biases that differ from those of human vision.</p>
        <div style="text-align: center">
            <img src="./img/EXP-attZ-distorted.jpg" alt="" width="990" style="margin: auto" />
        </div>
        <p class="section">&nbsp;</p>


        <p class="section"><b>III.  Latent Samples that Do Not Depict the Key Object but Correlated Background</b></p>
        <p> We find latent samples that generate objects commonly associated with the key object, rather than generating the key object class itself. It indicates a partial misalignment between the latent space and the prompt space. Furthermore, we demonstrate the correlation between this misalignment and the stability of diffusion models.</p>
        <div style="text-align: center">
            <img src="./img/EXP-attZ-unrelated.jpg" alt="" width="990" style="margin: auto" />
        </div>
        <p class="section">&nbsp;</p>


        <p class="section"><b>IV.  Universal Token Embeddings that Overwrite the Input Prompts</b></p>
        <p> We also find adversarial token embeddings, which only slightly change the CLIP score, but cause the diffusion model to produce irrelevant images. These adversarial embeddings are universal in the sense that they cause failures across a variety of input prompts. It also reveals potential safety concerns.</p>
        <div style="text-align: center">
            <img src="./img/EXP-attPrompt.jpg" alt="" width="990" style="margin: auto" />
        </div>
        <p class="section">&nbsp;</p>

        <hr class="hr-twill-colorful">

        <p class="section">&nbsp;</p>
        <p class="section"><b>More Results</b></p>
        <p> We provide additional representative text prompts that diffusion models cannot understand.</p>
        <div style="text-align: center">
            <img src="./img/Supp_text1.jpg" alt="" width="990" style="margin: auto" />
        </div>
        <div style="text-align: center">
            <img src="./img/Supp_text2.jpg" alt="" width="990" style="margin: auto" />
        </div>
        <div style="text-align: center">
            <img src="./img/Supp_text3.jpg" alt="" width="990" style="margin: auto" />
        </div>
        <div style="text-align: center">
            <img src="./img/Supp_text4.jpg" alt="" width="990" style="margin: auto" />
        </div>
        <div style="text-align: center">
            <img src="./img/Supp_text5.jpg" alt="" width="990" style="margin: auto" />
        </div>

        <!-- <p class="section">&nbsp;</p>
        <p class="section"><b>CVPR 2023 Video</b></p>
        <div style="text-align: center">
            <iframe width="75%" height="500px" src="https://www.youtube.com/embed/eemzbXXU59E" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
        </div> -->

        <!-- <p class="section">&nbsp;</p>
        <p class="section" id="paper"><b>Paper</b></p>
        <table width="940" border="0">
            <tbody>
                <tr>
                    <td height="100"><a href="https://arxiv.org/abs/2211.12572" target="_blank" rel="noopener noreferrer"><img
                                src="./sm/assets/paper_cover.jpeg" alt="" width="140" height="167"></a></td>
                    <td width="750">
                        <p><b>Plug-and-Play Diffusion Features for Text-Driven Image-to-Image Translation</b><br>
                            Narek Tumanyan <sup>*</sup>, Michal Geyer <sup>*</sup>, Shai Bagon, Tali Dekel.<br />
                            (* indicates equal contribution) <br>
                            [<a href="https://arxiv.org/abs/2211.12572" target="_blank"
                                rel="noopener noreferrer">paper</a>]</p>
                    </td>
                </tr>
            </tbody>
        </table> -->
        
        <!-- <p class="section">&nbsp;</p>
        <p class="section" id="sm"><b>Supplementary Material</b></p>
        <table width="587" height="136" border="0">
            <tbody>
                <tr>
                    <td width="180"><img src="./sm/assets/sm.png" alt="" height="150"></td>
                    <td align="left">
                        <p>[<a href="./sm/index.html" target="_blank">supplementary page</a>]</p>
                    </td>
                </tr>
            </tbody>
        </table> -->

        <p class="section">&nbsp;</p>
        <p class="section" id="bibtex"><b>Bibtex</b></p>
        <table border="0">
            <tbody>
                <pre style=" display: block;
                      background: #eee;
                      white-space: pre;
                      -webkit-overflow-scrolling: touch;
                      max-width: 100%;
                      min-width: 100px;
                      border-radius: 0px;
                      ">
@article{liu2023intriguing,
  title={Intriguing Properties of Text-guided Diffusion Models},
  author={Liu, Qihao and Kortylewski, Adam and Bai, Yutong and Bai, Song and Yuille, Alan},
  journal={arXiv preprint arXiv:2306.00974},
  year={2023}
}     
			  </pre>


            </tbody>
        </table>
    </div>



</body>

<script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-WLX2Z5QLG8');
 </script>
 <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
 <script type="text/javascript">
    $(document).ready(function () {

        if (localStorage.getItem("my_app_name_here-quote-scroll") != null) {
            $(window).scrollTop(localStorage.getItem("my_app_name_here-quote-scroll"));
        }

        $(window).on("scroll", function() {
            localStorage.setItem("my_app_name_here-quote-scroll", $(window).scrollTop());
        });

      });
 </script>

 <script>
    function prompt_on(prompt_element) {
        prompt_element.classList.add("caption-active");
    }

    function prompt_off(prompt_element) {
        prompt_element.classList.remove("caption-active");
    }

    function toggle_prompt(active_prompt_id, inactive_prompt_ids, result_id) {
        let active_prompt = document.getElementById(active_prompt_id);
        prompt_on(active_prompt);
        for (let i = 0; i < inactive_prompt_ids.length; i++) {
            let inactive_prompt = document.getElementById(inactive_prompt_ids[i]);
            prompt_off(inactive_prompt);
        }

        let result = document.getElementById(result_id);
        result.src = file_paths[active_prompt_id];
    }
 </script>

 <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
 <script src="https://cdn.jsdelivr.net/npm/popper.js@1.12.9/dist/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
 <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>

</html>
